# FAQ_RAG_chatbot
FAQ RAG (Retrieval Augmented Generation) Chatbot Project

## 목차

* [1. 요구 사항](#1-요구-사항)
* [2. 질의응답 시나리오 (데모)](#2-질의응답-시나리오-데모)
* [3. 문제 해결 접근 방법](#3-문제-해결-접근-방법)
  * [3-1. Chunking 전략](#3-1-chunking-전략)
  * [3-2. 임베딩 모델](#3-2-임베딩-모델)
  * [3-3. 검색 알고리즘](#3-3-검색-알고리즘)
  * [3-4. Chroma vs. FAISS](#3-4-chroma-vs-faiss)
  * [3-5. 무엇 (질문 or 답변) 을 'RAG으로 탐색할 문서'로 할 것인가?](#3-5-무엇-질문-or-답변-을-rag으로-탐색할-문서로-할-것인가)
* [4. 구현 방법](#4-구현-방법)
* [5. 성능 평가 (시스템 평가 및 검증)](#5-성능-평가-시스템-평가-및-검증)
* [6. 재현 가능성 (실행 가이드)](#6-재현-가능성-실행-가이드)

## 1. 요구 사항

* 네이버 스마트스토어 한글 FAQ 데이터 기반 챗봇 API 구현
* 요구 기능
  * [RAG (Retrieval-Augmented Generation)](https://github.com/WannaBeSuperteur/AI-study/blob/main/AI%20Basics/LLM%20Basics/LLM_%EA%B8%B0%EC%B4%88_RAG.md)
  * **스트리밍 방식** 의 챗봇 API 구현
  * **대화 기록 저장** 및 대화 맥락 기반 답변
  * 추가 요구사항
    * 답변 완료 후, 사용자가 궁금한 내용 추가 질문
    * 스마트스토어와 무관한 질문의 경우 **답변 불가 안내**

## 2. 질의응답 시나리오 (데모)

## 3. 문제 해결 접근 방법

* 주어진 ```final_result.pkl``` 파일에 대한 EDA 결과 (참고: [```eda.py```](eda.py))
* **질문 내용의 길이** 에 대한 통계

```
DOCUMENT LENGTH STATISTICS :
count : 2717
max   : 92
min   : 8
avg   : 36.04527051895473
std   : 12.966356507399645
```

### 3-1. Chunking 전략

* 최종 선택
  * **Recursive (상세 전략은 아래 참고)**

* 상세 전략
  * 각 대괄호 부분 + 나머지 부분으로 문서를 chunking
  * 예시
    * ```[가입절차][쇼핑윈도/패션타운] 네이버 쇼핑윈도 노출 절차는 어떻게 되나요?``` → ```[가입절차]```, ```[쇼핑윈도/패션타운]```, ```네이버 쇼핑윈도 노출 절차는 어떻게 되나요?``` 의 3개 부분으로 chunking
  * 해당 chunking 된 부분들 중 마지막 부분 (예: ```네이버 쇼핑윈도 노출 절차는 어떻게 되나요?```) 만을 **추가 chunking 없이** 사용

* 전략 적용 근거 
  * chunking 된 부분 중 마지막 부분만을 사용
    * **일반적인 사용자 경험** 상, 분류를 나타내는 대괄호 부분 (예: ```[가입절차]```) 을 굳이 넣지 않고 **해당 형태의 자연어 질문** 을 챗봇에게 하기 때문 
  * 마지막 부분에 대한 추가 chunking 미 적용
    * 대괄호 부분을 포함하더라도 전체 질문이 **평균 36자 정도로 매우 짧은 편**
    * 대괄호 부분을 제외하였으므로, 위 '평균 36자'보다도 질문이 짧아짐

| 전략                    | 전략 설명                              | 본 과제 적용 시 단점                                                                    |
|-----------------------|------------------------------------|---------------------------------------------------------------------------------|
| Fixed-Size            | **고정된 token 개수** 또는 글자 수로 문서 분할    | chunking으로 인해 단어가 중간에 분할 (예: ```스마트스``` ```토어 회원가입은...```) 되어 **의미 혼동 우려** 있음   |
| **Recursive (최종 채택)** | 문장/문단 등 **특정 구분자로 split** 하여 문서 분할 |                                                                                 |
| Semantic              | **의미가 바뀌는 부분을 AI로 판단** 하여 분할       | AI 모델 추가 사용에 따른 **연산량, 전체 구조 복잡도, 소요 시간 상향**                                    |
| Agentic               | **LLM을 통해 의미 단위를 판단** 하여 분할        | - AI 모델 추가 사용에 따른 **전체 구조 복잡도, 소요 시간 상향**<br>- 경우에 따라, API 사용에 따른 **약간의 비용** 발생 |

### 3-2. 임베딩 모델

* 최종 선택
  * ```telepix/PIXIE-Rune-Preview``` (from HuggingFace)
  * **0.6B** params
  * ```webfaq-retrieval``` 성능 **86.34 %**

* 선택 근거
  * 후보 선택: [한국어 오픈소스 임베딩 모델 리더보드](https://github.com/OnAnd0n/ko-embedding-leaderboard?tab=readme-ov-file#retrieval) 에서 다음 조건을 모두 만족시키는 모델
  * 모델 선정 기준 
    * **1.0B 이하** 파라미터 (사용자 프롬프트의 빠른 임베딩 → 응답 지연 방지) 
    * 위 조건을 만족시키는 모델 중 ```webfaq-retrieval``` (네이버 스마트스토어 FAQ와 가장 유사하다고 판단되는 컨셉의 데이터셋) 성능 값이 가장 큰 모델
  * OpenAI 등 유료 모델 대신 오픈소스 모델 사용 이유
    * 비용 절감
    * OpenAI 서비스 장애 시에도 원활한 작동 보장

### 3-3. 검색 알고리즘

* 최종 선택
  * **Vector Search (코사인 유사도 기반)**

* 선택 근거 (아래 표 참고)
  * Keyword Search가 적용된 경우, DB에 있는 질문의 일반명사 어휘가 사용자 프롬프트에 있는 동일 의미의 어휘와 달라서 (유의어) **적합한 문서를 놓칠 수 있음**
  * 예: ```가입 시 필요한 서류는 어디로 보내야 하나요?``` (DB) vs ```가입 시 필요한 문서의 제출처는 어디인가요?``` (사용자 프롬프트) → ```서류``` vs. ```문서```, ```어디로 보내야``` vs. ```제출처는 어디``` 등

| 검색 알고리즘        | 알고리즘 설명                                             | 본 과제 적용 시 장/단점                                                                                                                                                                        |
|----------------|-----------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Vector Search  | **의미적 유사성 (코사인 유사도)** 기반 (맥락 이해)                    | 장점: **자연어의 의미(의도)적 유사도** 고려 가능                                                                                                                                                        |
| Keyword Search | **단어의 정확한 일치 여부** 중심                                | - 장점: 사용자가 정보를 필요로 하는 **특정 키워드 (예: ```통신판매신고증```)** 에 집중 가능<br>- 단점: 일반명사 단어 사용이 DB의 Q&A와 사용자 프롬프트 간 달라서 (예: DB의 ```서류``` vs. 사용자 프롬프트의 ```문서```), 사용자의 의도에 맞는 문서의 '적합도 순위'가 낮아질 수 있음 |
| Hybrid Search  | 위 2가지 방법의 **혼합 사용**                                 | - 장점: 특정 키워드에 집중하면서도 자연어 의미 고려 가능<br>- 단점: Keyword Search의 단점인 **어휘 사용에 따른 '의도에 맞는 문서를 못 찾는' 문제** 가 여전히 존재                                                                            |

### 3-4. Chroma vs. FAISS

* 최종 선택
  * **Chroma DB**

* 선택 근거 (아래 표 참고)
  * MVP 형태의 챗봇을 **빠르게 구현** 해야 하므로, 구현이 쉬운 것이 중요
  * 전체 데이터 규모가 **약 2,700개의 중소 규모** 이므로, 대규모 데이터셋에 최적화할 필요 없음

| 도구                   | 구현 및 사용 편의성 | 최적의 데이터 규모             |
|----------------------|-------------|------------------------|
| **ChromaDB (최종 채택)** | 비교적 쉬움      | 비교적 작은 규모 데이터셋         |
| FAISS (Meta)         | 비교적 어려움     | 매우 큰 (백만~억 단위 이상) 데이터셋 |

### 3-5. 무엇 (질문 or 답변) 을 'RAG으로 탐색할 문서'로 할 것인가?

* 최종 선택
  * **질문 Only**

* 선택 근거
  * 사용자가 요청하는 내용 (프롬프트) 은 **질문** 에 해당
    * 사용자의 **질문** 에 대해, 마찬가지로 DB에 저장된 정보 중 **질문** 을 매칭시켜야, **DB의 정보 중 사용자의 의도에 가까운 문서를 정확히** 찾을 수 있음 
  * 일반적으로 질문이 답변보다 훨씬 짧으므로, 질문을 RAG으로 탐색할 문서로 지정 시 **RAG 알고리즘 사용 시의 연산량 절감** 가능

## 4. 구현 방법

## 5. 성능 평가 (시스템 평가 및 검증)

### 5-1. 평가를 위한 질문 리스트 (100개)

* 네이버 스마트스토어 한글 FAQ 데이터의 질문 (총 2,717건) 을 파일로 저장한 후, 해당 파일 기반으로 질문 추출 요청
  * **ChatGPT-5.2 Thinking** 모델 사용 (OpenAI API가 아닌, ChatGPT 웹사이트를 통해 ChatGPT 실행)
* 프롬프트

```
위 파일은 네이버 스마트스토어 FAQ의 질문 리스트이다.
이 질문 리스트를 기반으로 사용자가 할 만한 자연어 질문을 100개 만들어 줘.
(단, 원래 질문 리스트와 어휘 선택을 약간 다르게 한다.)
```

* [평가용 질문 리스트 (100개)](evaluation_question_list.txt)

### 5-2. 평가 코드

### 5-3. 평가 결과

## 6. 재현 가능성 (실행 가이드)

